# AI-BOM Workshop at RSA Conference 2024

AI software supply chain security is the bedrock of ensuring the integrity, authenticity, and resilience of AI systems throughout their lifecycle. AI-BOM, or AI Bill of Materials, is crucial for software supply chain security as it provides a comprehensive inventory of components within an AI system and properties of its security operations, MLSECOPS. AI-BOMs enable proactive measures to enhance security, mitigate threats, and maintain the integrity of AI systems. AI-BOM serves as a foundational tool for fostering trust, accountability, and resilience in the AI chain ecosystem.

Welcome to an enlightening afternoon at the AI-BOM Workshop, conveniently timed during the RSAC 2024. This exclusive workshop delves into the critical realm of AI software supply chain security. Expert speakers will illuminate key facets including AI-BOM and AI software supply chain security. Engage in collaborative discussions alongside industry leaders, shaping best practices and charting the path forward. With concluding remarks from a notable US government official from CISA.gov, this workshop ensures a comprehensive exploration of strategies to secure AI landscapes across all industries.


## Agenda
Doors open at 12:30 PM.
Registration: [AIBOM-workshop-RSAC2024](https://lu.ma/AIBOM-workshop-RSAC2024))

| Time       | Topic                                                               | Speaker                                   |
|------------|---------------------------------------------------------------------|-------------------------------------------|
| 1:00 PM    | Opening remarks                      | Sebastian Lange, CSO at SAP                          |
| 1:10 PM    | Lightning talks: on-going efforts on AIBOM in the community         |                                           |
|            | "What's Inside There? Model Metadata and Metrics for AI/ML BoMs"    | Diana Kelly and Sam Washko               |
|            | Recap on on-going workstreams on AI supply chain security from SPDX and CycloneDX          | Helen Oakley and Springett      |
|            | "AI Risk Assessment through Threat Modeling and use cases for AIBOM automation" | Helen Oakley    |
|            | "The State of AIBOMs: use cases, contents, regulations, and tools"  | Daniel Bardenstein                        |
|            | "Understanding vulnerabilities and weaknesses of AI"                | Dmitry Raidman                            |
|            | "AI Policy and Software Supply Chain: transparency and security for managing suppliers, services and product" | Nicholas Vidovich   |
|            |TBD | Alex Sharpe   |
| 2:20 PM    | Break                                                               |                                           |
| 2:35 PM    | Structured group discussion (details below) | |
| 3:35 PM    | Closing remarks by Allan Friedman, Senior Advisor and Strategist at CISA | Allan Friedman                        |
| 3:40 PM    | Networking                                                          |                                           |


## Structured Group Discussion

Attendees will divide into groups, each focusing on a specific topic. The initial 5 minutes will be dedicated to introductions, during which groups will select their representative. Subsequently, each group will delve into a 10-minute discussion on their topic. Afterward, each group will present their ideas and potential hurdles in a brief 2-3 minute pitch to the rest of the participants. The remaining time will be utilized for collective brainstorming to discuss furthermore the challenges and best practices. The result from this discussion will be documented on this page.

| Topic                                                                                        | Description                                                                                                        |
|----------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------|
| What fields should (and should not be) in an AIBOM? (e.g. model weights, visualizations of model performance) | This topic explores the essential and non-essential components to include in an AIBOM, such as model weights and visualizations of model performance. |
| Minimum elements                                                                           | Discusses the minimum set of elements required in an AIBOM to ensure comprehensive coverage and functionality.        |
| Collection of data for AIBOM properties (eg. about training)                                  | Examines the process of collecting and managing data for AIBOM properties, particularly focusing on training data.   |
| Standardized framework for AI dev & DevOps (MLOps) (E.g. model versioning)                   | Explores the development and DevOps practices necessary to establish a standardized framework for AI, including model versioning. |
| AI “Risks” and “Vulnerabilities” (as it pertains to fields in the AIBOM)                      | Analyzes the risks and vulnerabilities associated with AI systems, specifically in relation to the AIBOM fields.   |
| Creating or identifying infrastructure for AI risks a la NVD, CVE, CVSS, EPSS, KEV            | Discusses the establishment or identification of infrastructure similar to NVD, CVE, CVSS, EPSS, and KEV for managing AI-related risks. |
| AIBOM use cases (including biz operations & risk management)                                  | Explores various use cases of AIBOM in business operations and risk management to demonstrate its practical applications. |

